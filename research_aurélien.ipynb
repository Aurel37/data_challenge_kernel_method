{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "research.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dr1NlGJJ3Ra",
        "outputId": "b2797505-9354-4012-a85d-214e6ec93249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ],
      "source": [
        "# colab settings\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --quiet https://github.com/Aurel37/data_challenge_kernel_method.git"
      ],
      "metadata": {
        "id": "zcJIXdshJ62S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persistent_storage = 'drive/MyDrive/MVA/kernel/'"
      ],
      "metadata": {
        "id": "1EUu1Q50K-fz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eneFA7nlFwOi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "Xtr = np.array(pd.read_csv(persistent_storage + 'Xtr.csv',header=None,sep=',',usecols=range(3072)))\n",
        "Xte = np.array(pd.read_csv(persistent_storage + 'Xte.csv',header=None,sep=',',usecols=range(3072)))\n",
        "Ytr = np.array(pd.read_csv(persistent_storage + 'Ytr.csv',sep=',',usecols=[1])).squeeze()\n",
        "\n",
        "# define your learning algorithm here\n",
        "# for instance, define an object called ``classifier''  \n",
        "# classifier.train(Ytr,Xtr)\n",
        "\n",
        "\n",
        "# predict on the test data\n",
        "# for instance, Yte = classifier.fit(Xte)\n",
        "\n",
        "# next\n",
        "\n",
        "print(Xte[0, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgY0lP4YKPy7",
        "outputId": "2f8453d5-c800-4efd-b10d-fa4c465a9beb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.02131679 -0.02918767 -0.0217463  ... -0.0072958  -0.02088945\n",
            " -0.02422281]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_pict(image):\n",
        "    formatted = np.zeros((32, 32, 3))\n",
        "    formatted[:,:,0] = np.reshape(image[:1024], (32,32))\n",
        "    formatted[:,:,1] = np.reshape(image[1024:2048], (32,32))\n",
        "    formatted[:,:,2] = np.reshape(image[2048:3072], (32,32))\n",
        "    plt.imshow(formatted)\n",
        "display_pict(Xtr[0, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "d4bhx_fWFLPS",
        "outputId": "c8bc95f3-032b-4431-d69b-152dacc0927a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feature finder\n",
        "# PCA ? GRadient truc ? "
      ],
      "metadata": {
        "id": "7opw9bw5JyUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.array([0, 3, 5, 4])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "AWlGw8CpEVyb",
        "outputId": "573da918-010c-4da5-c1ca-a694f4cad571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-49b660e8e30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader:\n",
        "\n",
        "    def __init__(self, dataset, target, batch_size=1, shuffle=False):\n",
        "        if not(target.shape[0] == dataset.shape[0]):\n",
        "            raise ValueError(\"target and dataset must have same x-axis size\")\n",
        "        N = dataset.shape[0]\n",
        "        self.dataset_raw = dataset.copy()\n",
        "        self.target_raw = target.copy()\n",
        "        if shuffle:\n",
        "            arange = np.arange(N)\n",
        "            self.dataset = np.split(dataset[arange, :], batch_size)\n",
        "            self.target = np.split(target[arange], batch_size)\n",
        "        else:\n",
        "            self.dataset = np.split(dataset, batch_size)\n",
        "            self.target = np.split(target, batch_size)\n",
        "        self.n_batch = len(self.target)\n",
        "        self.it = None\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "      \n",
        "    def __iter__(self):\n",
        "        self.it = -1\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.it + 1 < self.n_batch:\n",
        "            self.it += 1\n",
        "            return self.dataset[self.it], self.target[self.it]\n",
        "        else:\n",
        "            raise StopIteration\n",
        "    \n",
        "    def copy(self):\n",
        "        dataset = self.dataset_raw.copy()\n",
        "        target = self.target_raw.copy()\n",
        "        return DataLoader(dataset, target, self.batch_size, self.shuffle)"
      ],
      "metadata": {
        "id": "ViqPuUZ6kvc1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.linalg import eigh\n",
        "\n",
        "class KernelPCA:\n",
        "\n",
        "    def __init__(self, dataloader, kernel, n_dim):\n",
        "        self.dataloader = dataloader.copy()\n",
        "        self.n_batch = dataloader.n_batch\n",
        "\n",
        "        # kernel should be a function here\n",
        "        self.kernel = kernel\n",
        "        self.n_dim = n_dim\n",
        "    \n",
        "    def center_kernel(self, X):\n",
        "        N, _ = X.shape\n",
        "        kernel_mat = self.kernel(X, X)\n",
        "        ones_N = 1/N*np.ones((N, N))\n",
        "        return kernel_mat - ones_N@kernel_mat - kernel_mat@ones_N + ones_N@kernel_mat@ones_N\n",
        "    \n",
        "    def PCA(self, X):\n",
        "        K = self.center_kernel(X)\n",
        "        eigenvals, eigenvects = eigh(K)\n",
        "\n",
        "        # remove the eigenvectors associated to 0\n",
        "        # it's a sanity check, should never occur\n",
        "        non_zero = eigenvals != 0\n",
        "        eigenvals = eigenvals[non_zero]\n",
        "        eigenvects = eigenvects[non_zero, :]\n",
        "\n",
        "        # sort eigenvalues in descending order to retrieve \n",
        "        # the first n_dim eigenvect\n",
        "        order_eigh = eigenvals.argsort()[::-1]\n",
        "        order_eigh = order_eigh[:self.n_dim]\n",
        "\n",
        "        alpha = eigenvects[order_eigh, :].T/np.sqrt(eigenvals[order_eigh])\n",
        "        return np.dot(K, alpha)\n",
        "\n",
        "    def project(self):\n",
        "        for i in range(self.n_batch):\n",
        "            self.dataloader.dataset[i] = self.PCA(self.dataloader.dataset[i])\n",
        "        return self.dataloader"
      ],
      "metadata": {
        "id": "EiEUgfmP4sTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(Xtr, Ytr, 500)"
      ],
      "metadata": {
        "id": "TTdc2rQ07Ojd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RBF:\n",
        "    def __init__(self, sigma=1.):\n",
        "        self.sigma = sigma  ## the variance of the kernel\n",
        "        #self.k = None\n",
        "        \n",
        "    def kernel(self,X,Y):\n",
        "        ## Input vectors X and Y of shape Nxd and Mxd\n",
        "        \n",
        "        # difference between all vectors X and Y\n",
        "        xmy = X[:, None, :] - Y[None, :, :]\n",
        "        #self.k = xmy\n",
        "        return np.exp(-1/2*np.square(np.linalg.norm(xmy, axis=2)/self.sigma))"
      ],
      "metadata": {
        "id": "O0pLdVBbhWDo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbf = RBF(1)\n",
        "rbf.kernel(Xtr, Xtr)"
      ],
      "metadata": {
        "id": "LrG25hIx7grL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import optimize\n",
        "\n",
        "class KernelSVC:\n",
        "    \n",
        "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
        "        self.type = 'non-linear'\n",
        "        self.C = C                               \n",
        "        self.kernel = kernel        \n",
        "        self.alpha = None\n",
        "        self.support = None\n",
        "        self.epsilon = epsilon\n",
        "        self.norm_f = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        #### You might define here any variable needed for the rest of the code\n",
        "        N = len(y)\n",
        "        diag_y = np.zeros((N,N))\n",
        "        for i in range(N):\n",
        "            diag_y[i,i] = y[i]\n",
        "        one = np.ones(N)\n",
        "        K = self.kernel(X, X)\n",
        "        # Lagrange dual problem\n",
        "        \n",
        "        def loss(alpha):\n",
        "            return  -2*alpha.T@y+alpha.T@K@alpha\n",
        "\n",
        "        # Partial derivate of Ld on alpha\n",
        "        def grad_loss(alpha):\n",
        "            return -2*y + 2*K@alpha\n",
        "\n",
        "        # Constraints on alpha of the shape :\n",
        "        # -  d - C*alpha  = 0\n",
        "        # -  b - A*alpha >= 0\n",
        "\n",
        "        fun_eq = lambda alpha: alpha.T@one    \n",
        "        jac_eq = lambda alpha: one\n",
        "        fun_ineq_0 = lambda alpha: -alpha*y + self.C*one\n",
        "        jac_ineq_0 = lambda alpha:  -diag_y\n",
        "        fun_ineq_1 = lambda alpha: alpha*y\n",
        "        jac_ineq_1 = lambda alpha:  diag_y\n",
        "        \n",
        "        constraints = ({'type': 'eq',  'fun': fun_eq, 'jac': jac_eq},\n",
        "                       {'type': 'ineq', \n",
        "                        'fun': fun_ineq_0 , \n",
        "                        'jac': jac_ineq_0}, \n",
        "                       {'type': 'ineq', \n",
        "                        'fun': fun_ineq_1, \n",
        "                        'jac': jac_ineq_1}, \n",
        "                      )\n",
        "\n",
        "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
        "                                   x0=np.ones(N), \n",
        "                                   method='SLSQP', \n",
        "                                   jac=lambda alpha: grad_loss(alpha), \n",
        "                                   constraints=constraints)\n",
        "        self.alpha = optRes.x\n",
        "        \n",
        "        # support indices\n",
        "        supportIndices = np.where(np.abs(self.alpha) > self.epsilon)  \n",
        "        self.alpha = self.alpha[supportIndices]\n",
        "        y_support = y[supportIndices]\n",
        "        self.support = X[supportIndices] #'''------------------- A matrix with each row corresponding to a support vector ------------------'''\n",
        "        \n",
        "        K = self.kernel(self.support, self.support)\n",
        "        \n",
        "        # compute b\n",
        "        \n",
        "        # index of alpha_i to compute b using \n",
        "        # the complementary slackness conditions\n",
        "        kkt_index = np.argmax((self.alpha > 0)*(self.alpha < y_support*self.C))\n",
        "        self.b = y_support[kkt_index] - self.separating_function(np.array([self.support[kkt_index]]))\n",
        "        \n",
        "        # compute the norm of f\n",
        "        self.norm_f = np.sqrt(self.alpha.T@K@self.alpha)\n",
        "        \n",
        "    ### Implementation of the separting function $f$ \n",
        "    def separating_function(self,x):\n",
        "        # Input : matrix x of shape N data points times d dimension\n",
        "        # Output: vector of size N\n",
        "        return  self.kernel(x, self.support)@self.alpha\n",
        "    \n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
        "        d = self.separating_function(X)\n",
        "        return 2 * (d+self.b > 0) - 1"
      ],
      "metadata": {
        "id": "o8QMrPOZ2RfL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(batch_size, n_dim, kernel, param_kernel, n_class=10):\n",
        "    kernel_func = kernel(param_kernel).kernel\n",
        "    dataloader = DataLoader(Xtr, Ytr, batch_size)\n",
        "    dataloader_pca = KernelPCA(dataloader, kernel_func, n_dim)\n",
        "    SVMs = []\n",
        "    for in range(n_class):\n",
        "        "
      ],
      "metadata": {
        "id": "44AjCJIm2vFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}